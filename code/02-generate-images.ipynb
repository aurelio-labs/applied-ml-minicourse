{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02: Generating Images with Diffusion\n",
    "\n",
    "In this chapter we'll take a look at the applied method for generating images with diffusion. For this we'll be using Hugging Face's *Diffusers* library.\n",
    "\n",
    "## The Hugging Face ML Ecosystem\n",
    "\n",
    "Hugging Face is an organization that has built a huge number of ML libraries, released models, datasets, and much more. When working in ML, Hugging Face provides a incredible useful and open-source ecosystem of tools.\n",
    "\n",
    "*Diffusers* is one of their latest libraries. The focus is on easy use of diffuser models, including the hugely popular *Stable Diffusion* models from *Stability AI*.\n",
    "\n",
    "We can get started with a `pip install` of the required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq diffusers transformers --extra-index-url https://download.pytorch.org/whl/cu113 torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we move on to the `StableDiffusionPipeline`.\n",
    "\n",
    "## Stable Diffusion\n",
    "\n",
    "Stable diffusion is not a single model but multiple models and transformations performed several times. Overall the process looks like:\n",
    "\n",
    "![Stable Diffusion pipeline](https://github.com/jamescalam/applied-ml-minicourse/raw/main/images/stable-diffusion-pipeline-annotated.png)\n",
    "\n",
    "Fortunately we don't need to worry about putting each of these together, at least not yet. The `diffusers` library includes a `StableDiffusionPipeline` object that will automatically build this pipeline of models and transformations. All we need to do is provide an input prompt that will be used to generate images.\n",
    "\n",
    "We initialize the pipeline like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# init all of the pipeline models\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "  \tuse_auth_token=\"<<ACCESS_TOKEN>>\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing above is that you must use a *user access token* to use the stable diffusion models. These can be found in *user settings* after creating an account on [Hugging Face](https://huggingface.co/).\n",
    "\n",
    "If you're struggling to do this, refer to the relevant course video *or* follow [this guide on Hugging Face access tokens](https://huggingface.co/docs/hub/security-tokens).\n",
    "\n",
    "Once you have authenticated and downloaded the pipeline (`pipe`), we can begin generating images. However, it will be slow on the default CPU hardware. If possible, we should switch to a CUDA-enabled GPU like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# set the hardware device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# move pipeline to chosen device\n",
    "pipe.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a person surfing\"\n",
    "\n",
    "out = pipe(prompt)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we return a `StableDiffusionPipelineOutput` object that contains `images` and `nsfw_content_detected` lists. In `images` we should see a single *PIL* image object (just one because we passed just one prompt). We can view it like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = out.images[0]\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we can see that we've generated an image of a person surfing, as intended.\n",
    "\n",
    "There is much more to the `StableDiffusionPipeline` than just this as we will explore in later chapters. For now, we've covered the core functionality of generating images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
