{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jamescalam/applied-ml-minicourse/blob/main/code/09-making-queries.ipynb)\n",
    "\n",
    "# 09: Making Queries\n",
    "\n",
    "Now that we have our data indexed in both Pinecone and Cloud Storage, we can move on to making queries.\n",
    "\n",
    "<img src=\"https://github.com/jamescalam/applied-ml-minicourse/raw/main/images/hf-spaces-cacher-components.png\" style=\"width:80%\">\n",
    "\n",
    "The image above shows the intended structure of our app. Every time a user makes a query we will first search for past queries that have been made and have a high similarity to the new query.\n",
    "\n",
    "If we find a past query aligns with the current query we can skip the long diffusion process and simply return a few of the most similar past queries.\n",
    "\n",
    "Let's see how to perform these queries.\n",
    "\n",
    "## Initializing Services\n",
    "\n",
    "Again, as usual, we must initialize our connection to Cloud Storage, Pinecone, and initialize the `StableDiffusionPipeline`.\n",
    "\n",
    "Starting with Cloud Storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import storage\n",
    "\n",
    "# set credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'cloud-storage.json'\n",
    "\n",
    "# connect to bucket (we named it 'diffusion')\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket('diffusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone.init(\n",
    "    api_key='<<YOUR_API_KEY>>',\n",
    "    environment='us-west1-gcp'\n",
    ")\n",
    "\n",
    "# connect to index\n",
    "index = pinecone.Index('diffusion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `StableDiffusionPipeline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# set the hardware device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# init all of the pipeline models and move them to a given GPU\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    \"CompVis/stable-diffusion-v1-4\",\n",
    "  \tuse_auth_token=\"<<ACCESS_TOKEN>>\"\n",
    ")\n",
    "pipe.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make some queries.\n",
    "\n",
    "## Making Queries\n",
    "\n",
    "When making queries we must use the first two components of the pipeline, the tokenizer and CLIP, to create a *query prompt vector*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a person surfing\"\n",
    "\n",
    "# encode prompt to mean_pooled vector\n",
    "tokens = pipe.tokenizer(\n",
    "    prompt, padding='max_length',\n",
    "    return_tensors='pt'\n",
    ").to(device)\n",
    "xq = pipe.text_encoder(**tokens)['mean_pooled'].detach().cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the query to Pinecone, we will return the top `5` most similar matches *and* return the prompt metadata.\n",
    "\n",
    "<img src=\"https://github.com/jamescalam/applied-ml-minicourse/raw/main/images/making-queries.png\" style=\"width:60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xc = index.query(xq, top_k=5, include_metadata=True)\n",
    "xc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the ID values so that we can download the images from Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [match['id'] for match in xc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we download all of the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "images = []\n",
    "\n",
    "for _id in ids:\n",
    "    # connect to cloud storage blob and download\n",
    "    blob = bucket.blob(f\"{_id}.png\").download_as_string()\n",
    "    # convert to 'in-memory' file\n",
    "    blob_bytes = io.BytesIO(blob)\n",
    "    # convert to PIL image object\n",
    "    im = Image.open(blob_bytes)\n",
    "    images.append(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now view the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in images:\n",
    "    im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that is how we make queries to our vector database and use the results to retrieve the most relevant images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
